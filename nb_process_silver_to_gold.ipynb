{"cells":[{"cell_type":"code","source":["# nb_process_silver_to_gold (Final Version)\n","\n","# ------------------------------\n","# 0Ô∏è‚É£ Load config, logging, functions\n","# ------------------------------"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6a52d23f-c6fd-42cd-9637-73f2914fb36f"},{"cell_type":"code","source":["%run ./nb_config\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"03234b70-a632-449e-ae2a-2d50835d0265","normalized_state":"finished","queued_time":"2026-01-05T14:06:28.2033916Z","session_start_time":"2026-01-05T14:06:28.2037922Z","execution_start_time":"2026-01-05T14:06:41.501721Z","execution_finish_time":"2026-01-05T14:06:41.5597379Z","parent_msg_id":"71fd1da6-091e-4e50-9e17-66b3eeec5495"},"text/plain":"StatementMeta(, 03234b70-a632-449e-ae2a-2d50835d0265, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Config Loaded Successfully\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a74c42ce-a001-469b-b21e-5cf79741dc2d"},{"cell_type":"code","source":["%run ./nb_logging\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[4,5],"state":"finished","livy_statement_state":"available","session_id":"03234b70-a632-449e-ae2a-2d50835d0265","normalized_state":"finished","queued_time":"2026-01-05T14:06:43.136385Z","session_start_time":null,"execution_start_time":"2026-01-05T14:06:44.3994351Z","execution_finish_time":"2026-01-05T14:06:44.4594535Z","parent_msg_id":"8fb5b041-e928-4efa-8b4f-fffaf15213db"},"text/plain":"StatementMeta(, 03234b70-a632-449e-ae2a-2d50835d0265, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2026-01-05 14:06:44 - nb_logging - INFO - Logging notebook initialized successfully.\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"869a605b-8eed-43ae-9921-275eedbf9ada"},{"cell_type":"code","source":["%run nb_functions"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[6,7,8],"state":"finished","livy_statement_state":"available","session_id":"03234b70-a632-449e-ae2a-2d50835d0265","normalized_state":"finished","queued_time":"2026-01-05T14:06:47.0779776Z","session_start_time":null,"execution_start_time":"2026-01-05T14:06:48.3251413Z","execution_finish_time":"2026-01-05T14:06:48.4006319Z","parent_msg_id":"e345fca6-091e-489e-8112-36e5cd287761"},"text/plain":"StatementMeta(, 03234b70-a632-449e-ae2a-2d50835d0265, 8, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"04873fea-42f9-48c9-ba5d-35ed595eb0de"},{"cell_type":"code","source":["from pyspark.sql.functions import col, avg, when, lit, current_timestamp, round\n","from pyspark.sql import Window\n","from pyspark.sql.functions import year, month, dayofmonth, hour, col, avg, round\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"03234b70-a632-449e-ae2a-2d50835d0265","normalized_state":"finished","queued_time":"2026-01-05T14:06:50.2234099Z","session_start_time":null,"execution_start_time":"2026-01-05T14:06:50.2243874Z","execution_finish_time":"2026-01-05T14:06:50.6560337Z","parent_msg_id":"e9d08ee4-321b-403e-a953-aee094334721"},"text/plain":"StatementMeta(, 03234b70-a632-449e-ae2a-2d50835d0265, 9, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"519bd3dd-a676-49c5-8b8b-ccbc6b7bb628"},{"cell_type":"code","source":["# =========================================================================\n","# 1. SETUP & CONFIGURATION\n","# =========================================================================\n","# We use the parameters you provided to maintain consistency across the project.\n","\n","# Loading Settings\n","is_full_load = False\n","FROM_DATE = '2025-01-01'\n","TARGET_TABLE_NAME = \"SmartCity_Analysis\"\n","\n","# Data Source & Target Paths\n","_SOURCE = \"smart_city\"       \n","FILE_FORMAT = \"delta\"        \n","DOMEIN_CATEGORY = \"analytics\" \n","_DOMEIN = \"energy_reports\"   \n","\n","# Metadata Column Constants\n","PRIM_COL_NAME = \"_id\"\n","SOURCE_COL_NAME = \"_source\"\n","IMPORTDATE_COL_NAME = \"_datetime_import\"\n","\n","logger = get_logger(__name__)\n","logger.info(\"üöÄ Starting Gold Layer Process: Smart City Decision Engine\")\n","\n","# =========================================================================\n","# 2. RELATIONSHIP METADATA\n","# =========================================================================\n","# This dictionary maps how different tables relate. \n","# It allows the loop in Block 4 to join tables automatically.\n","join_configs = {\n","    \"energy_weather\": {\n","        \"right_dataset\": \"weather_config\", \n","        \"join_key\": \"time\", \n","        \"how\": \"left\"\n","    },\n","    \"energy_air_quality\": {\n","        \"right_dataset\": \"air_quality_config\", \n","        \"join_key\": \"time\", \n","        \"how\": \"left\"\n","    }\n","}\n","\n","# Initialize the state-management dictionary\n","dataframe_collection = {\"prepared\": {}, \"gold\": {}}\n","\n","# =========================================================================\n","# 3. LOAD & PREPARE (Silver to Collection)\n","# =========================================================================\n","# We loop through the source_configs from your nb_config to load data.\n","for source_name, configs in source_configs.items():\n","    # PATH: We use the destination path from Silver (LKHS_PATH_DES)\n","    src_path = f\"{LKHS_PATH_DES}{configs['sink']['sink_directory']}\"\n","    \n","    try:\n","        # Load Silver Delta table\n","        df = spark.read.format(FILE_FORMAT).load(src_path)\n","        \n","        # 1. Selection: Use the safe select helper from your nb_functions\n","        if 'columns_to_select' in configs:\n","            df = select_columns_safe(df, configs['columns_to_select'])\n","            \n","        # 2. Time Enrichment: Standardize time for Power BI filtering\n","        df = df.withColumn(\"year\", year(col(\"time\"))) \\\n","               .withColumn(\"month\", month(col(\"time\"))) \\\n","               .withColumn(\"day\", dayofmonth(col(\"time\"))) \\\n","               .withColumn(\"hour\", hour(col(\"time\")))\n","               \n","        dataframe_collection[\"prepared\"][source_name] = df\n","        logger.info(f\"üì• Prepared {source_name} for integration.\")\n","        \n","    except Exception as e:\n","        logger.error(f\"‚ùå Failed to load {source_name} from {src_path}: {e}\")\n","\n","# =========================================================================\n","# 4. DYNAMIC INTEGRATION (The Join Loop)\n","# =========================================================================\n","# We take 'energy_config' as the primary table and join others to it.\n","base_key = \"energy_config\"\n","\n","if base_key in dataframe_collection[\"prepared\"]:\n","    final_df = dataframe_collection[\"prepared\"][base_key]\n","    \n","    for join_name, config in join_configs.items():\n","        right_key = config[\"right_dataset\"]\n","        \n","        if right_key in dataframe_collection[\"prepared\"]:\n","            right_df = dataframe_collection[\"prepared\"][right_key]\n","            \n","            # ANTI-COLLISION: Remove columns already in the base table \n","            # (like year, month, day) to avoid \"Ambiguous Column\" errors.\n","            cols_to_drop = [c for c in right_df.columns if c in final_df.columns and c != config[\"join_key\"]]\n","            right_df = right_df.drop(*cols_to_drop)\n","            \n","            # Execute the Join based on metadata\n","            final_df = final_df.join(right_df, on=config[\"join_key\"], how=config[\"how\"])\n","            logger.info(f\"üîó Integrated {right_key} using {config['join_key']}\")\n","            \n","    dataframe_collection[\"gold\"][\"merged_data\"] = final_df\n","else:\n","    logger.error(\"üö´ Base dataset (energy_config) missing. Join cannot proceed.\")\n","    raise Exception(\"Base dataset missing.\")\n","\n","# =========================================================================\n","# 5. SCORING & BUSINESS LOGIC\n","# =========================================================================\n","# Here we apply the Smart City specific analysis.\n","df_scored = dataframe_collection[\"gold\"][\"merged_data\"]\n","\n","# A. Trend Calculation: 3-hour moving average of price\n","window_spec = Window.orderBy(\"time\").rowsBetween(-3, 0)\n","df_scored = df_scored.withColumn(\"avg_price_3h\", round(avg(col(\"price\")).over(window_spec), 4))\n","\n","# B. Environmental & Economic Scoring\n","PM10_LIMIT = 50.0\n","df_scored = df_scored.withColumn(\n","    \"clean_energy_score\",\n","    round((col(\"wind_speed_10m\") * 1.5) - (col(\"pm10\") * 0.5) - (col(\"carbon_monoxide\") * 0.1), 2)\n",").withColumn(\n","    \"opportunity_status\",\n","    when(col(\"pm10\") > PM10_LIMIT, lit(\"Unsafe: Air Pollution\"))\n","    .when((col(\"price\") < col(\"avg_price_3h\")) & (col(\"wind_speed_10m\") > 15), lit(\"Opportunity\"))\n","    .otherwise(lit(\"Normal\"))\n",").withColumn(\n","    \"recommendation\",\n","    when(col(\"opportunity_status\") == \"Unsafe: Air Pollution\", \"STAY INDOORS: Avoid energy-intensive tasks\")\n","    .when((col(\"opportunity_status\") == \"Opportunity\") & (col(\"clean_energy_score\") > 30), \"High Priority: Cheap & Green\")\n","    .when(col(\"opportunity_status\") == \"Opportunity\", \"Medium Priority: Cheap but Dirty\")\n","    .otherwise(\"Wait for better conditions\")\n",")\n","\n","# C. Final Cleanup: Select only report columns (Drops metadata like _id, _source)\n","report_columns = [\n","    'time', 'year', 'month', 'day', 'hour', \n","    'price', 'avg_price_3h', 'wind_speed_10m', 'direct_radiation', \n","    'carbon_monoxide', 'pm10', 'clean_energy_score', \n","    'opportunity_status', 'recommendation'\n","]\n","df_gold_final = select_columns_safe(df_scored, report_columns)\n","\n","# =========================================================================\n","# 6. PERSISTENCE (Saving to Gold Table)\n","# =========================================================================\n","try:\n","    # Construct Gold Sink Path\n","    gold_sink_path = f\"{PATH_GOLD}/smart_city_decisions\"\n","    \n","    # Save using your nb_functions helper\n","    # We use 'time' as the primary key for the merge logic in Gold.\n","    load_data_into_delta_table(\n","        data=df_gold_final, \n","        sink_path=gold_sink_path, \n","        full_load=True, \n","        primary_col_name=\"time\"\n","    )\n","\n","    # Register in Lakehouse Catalog for Power BI\n","    table_name = f\"gold_smart_city_decisions\"\n","    create_lakehouse_table(table_name, gold_sink_path)\n","    spark.sql(f\"REFRESH TABLE {table_name}\")\n","\n","    logger.info(f\"‚úÖ Gold Process Complete: {table_name} is ready for Power BI.\")\n","    logger.info(f\"üìä Final Row Count: {df_gold_final.count()}\")\n","\n","except Exception as e:\n","    logger.error(f\"‚ùå Error during Gold persistence: {str(e)}\")\n","    raise e"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"03234b70-a632-449e-ae2a-2d50835d0265","normalized_state":"finished","queued_time":"2026-01-05T14:06:52.7925678Z","session_start_time":null,"execution_start_time":"2026-01-05T14:06:52.7937773Z","execution_finish_time":"2026-01-05T14:07:23.2647125Z","parent_msg_id":"ad1558e3-e88e-4b46-989f-ed4b89186cf1"},"text/plain":"StatementMeta(, 03234b70-a632-449e-ae2a-2d50835d0265, 10, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2026-01-05 14:06:52 - __main__ - INFO - üöÄ Starting Gold Layer Process: Smart City Decision Engine\n2026-01-05 14:06:54 - __main__ - INFO - üì• Prepared energy_config for integration.\n2026-01-05 14:06:55 - __main__ - INFO - üì• Prepared weather_config for integration.\n2026-01-05 14:06:56 - __main__ - INFO - üì• Prepared air_quality_config for integration.\n2026-01-05 14:06:56 - __main__ - INFO - üîó Integrated weather_config using time\n2026-01-05 14:06:56 - __main__ - INFO - üîó Integrated air_quality_config using time\n2026-01-05 14:07:20 - __main__ - INFO - ‚úÖ Gold Process Complete: gold_smart_city_decisions is ready for Power BI.\n2026-01-05 14:07:21 - __main__ - INFO - üìä Final Row Count: 1415\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"049e1aad-1b95-4c6c-aaf7-b24be12dfbcd"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"880a2fb2-8672-4c97-a3a0-56f067dc2207","known_lakehouses":[{"id":"880a2fb2-8672-4c97-a3a0-56f067dc2207"}],"default_lakehouse_name":"smart_city_lakehouse","default_lakehouse_workspace_id":"ce7fad14-2d0e-40e4-8c22-a560e4ffafd3"}}},"nbformat":4,"nbformat_minor":5}